Autoheuristic: add config options for specifying optimizations to collect data for and use heuristics (#130245)
Fix mm pad regresion - more conservative estimation of plannable inputs (#128909)
[inductor] Avoid fallback case for custom scan op lowering (#130936)
Autoheuristic: Do not store choices as metadata (#130304)
[inductor][cpp][gemm] move bias add to epilogue (#130675)
Refactored flexattention kernel (#130904)
[inductor] Fix the method for checking the variable type of entry.numel (#131026)
[Inductor] B2B-GEMM performance tuning with test (#130778)
[inductor] Separate Buffer and Operation into two concepts (#130831)
[inductor] parallel compile: Create new pipes for subproc communication (#131194)
[inductor][cpp][gemm] optimize arbitrary N in packed gemm template (#130690)
[inductor] [cpp] improve cache blocking with CPU info (#129348)
[BE][Easy][16/19] enforce style for empty lines in import segments in torch/_i*/ (#129768)
[Inductor] Support store SPIR-V binary file output from Intel Triton. (#130849)
[aoti] refactor aoti_torch__scaled_mm and skip aoti fp8 test for some cases (#130868)
Annotate graph.py (#131400)
[Inductor] Allow customize decompositions for fwd_only trace function (#131329)
Divorce triton and pt2 remote caching (#131345)
Ensure non-contiguous indices are handled (#131430)
[4/N] Non-Tensor: Support layout, device and dtype for aten operations (#125897)
[BE][Inductor] fix do_bench test (#131402)
[BE][Inductor] fix failures in test_padding.py (#131417)
[inductor][cpp][gemm] improve thread blocking heuristics (#131024)
Add mypy typing to pattern_matcher (#131506)
Dont wrap negative indexing in scatter reduce (#131503)
[AOTI] Support fallback ops not in inductor_fallback_ops (#131247)
[BE] Annotate subgraph_lowering (#131545)
[inductor] Fix flaky tests in test_memory_planning.py (#131703)
[inductor] Fix flaky tests in test_benchmark_fusion.py (#131733)
[inductor] Fix flaky tests in test_pad_mm (#131699)
[BE][inductor] Type annotate codecache.py and config.py (#131427)
[inductor] Fix flaky tests in test_debug_trace.py (#131722)
[inductor] Fix flaky tests in test_select_algorithm.py (#131709)
[inductor][cpp][gemm] support k slicing for static shapes (#130821)
Factor out cudagraph post compile into its own function (#129384)
[inductor] Refactor fusion of inplace operations (#130835)
[Inductor] Added and_masks and or_masks utilities & make fully masked out rows 0 instead of nan (#131552)
[inductor][autotune_at_compile_time] support Triton kernel with sympy fn str arg (#131253)
[inductor][autotune_at_compile_time] fix some codegen-ing for standalone autotuning file (#131726)
[CUDAGraph] Type annotation for cudagraph_trees.py (#131621)
[inductor] update users to buffers instead of scheduler nodes (#131796)
[inductor] Add type hints to functions in decompositions.py (#131780)
[CUDAGraph] Type annotation for cudagraph_trees.py (#131621)
[inductor] Fix duplicated range tree codegen in split scan (#131669)
AutoHeuristic: Add support for kernel choice selection (#131610)
[AOTI] Fix _mm_plus_mm codegen (#131689)
[Inductor][CPU] Fix an InvalidVecISA issue on CI (#131812)
[aoti] Fix float16 and bfloat16 for generated GPU code (#131437)
[inductor] enable windows inductor UTs (#131767)
[inductor] enhance cpp_builder lint check. (#131752)
[Traceable FSDP2][Inductor] Create grouped nodes for FSDP2 all-gather code block and reduce-scatter code block (after Buffer/Operation split) (#131510)
[Traceable FSDP2][Inductor] Apply compute/comm reordering passes to achieve overlap (#131614)
[Inductor] supporting pointwise intermediate nodes in B2B-GEMM (#131685)
[inductor] Add type hints to functions in debug.py (#131836)
[inductor] Fix flaky tests in test_aot_inductor.py (#131994)
[inductor] Handle NoneLayout in count_numel (#131645)
Cpp wrapper: set args to CppWrapperKernelArgs in cpp template kernel (#129557)
[cpp-wrapper] create null pointer for zero-size array (#132023)
[inductor] Replace self_cuda_time_total function calls with self_devâ€¦ (#131029)
[Inductor][CPP] Enhance cppcsevar data type deduce (#130827)
Optimize aten.cat calls of a repeated element (#132081)
[inductor] validate_can_generate_cpp_wrapper add win32 support. (#131978)
[inductor] optimize cflags for Windows. (#131980)
[inductor] turn on enable_kernel_profile on Windows. (#132025)
[Inductor][FlexAttention] Correct partial/full blocks naming (#131993)
[inductor] fix the cudagraph tree test (#132043)
Don't try hard to compute alignment of unbacked expressions (#131649)
Add lowering for updated _scaled_mm (fixing submodules) (#130422)
[Inductor][CPP] Fix Local Buffer issue with inplace result line (#132018)
[inductor] fix scalar miss constuctor for long type. (#132117)
[inductor] skip remote fx caching in failing pattern matcher tests (#132206)
typing ir.py - part 1 (#131845)
Save and run post compilation steps within FXGraphCache (#130572)
Fix lint after PR #130572 (#132316)
Refactor local autotune remote cache to make the code less error prone (#132289)
[inductor][cpp] stabilize do_bench_cpu (#131873)
Add Full block support to flex_decoding (#131404)
[inductor] fix UndefinedTensorImpl singleton can't export on Windows. (#132326)
[inductor] cpp codegen alignas for all OSs. (#132387)
[inductor] make restrict_keyword cross OSs. (#132394)
[AOTI] Fix a typo in ExternKernel.codegen_const_args (#132191)
Cast inputs to low precision kernels in emulate low precision mode (#132345)
[AOTI] Fix number type for AOTI (#132180)
[inductor] contine to fix restrict keyword. (#132463)
Fix file lock issue in AotCodeCompiler (#132343)
[Inductor][FlexAttention] Add kwarg to top level for users to specify kernel params (#132015)
[inductor] Reland: Add flag to ignore unsupported @triton.autotune args in user-written kernel compilation (#132562)
[inductor] check compiler exist on Windows. (#132533)
[Inductor][FlexAttention] TestFlexAttention -> TestFlexDecoding (#132547)
[inductor] use uint64_t replace long to add Windows support. (#132491)
[Inductor][CPP] Add vectorization support for double (#131886)
[inductor] add msvc_cl compiler check (#132571)
[inductor] support vectorization for torch.argmax/min(float/int64_t)-> int64_t (#131016)
add missing profiler include in cpp code generation (#132419)
[inductor] Fix autotune non-close attr crash on Windows (#132630)
[inductor] unificate SUBPROCESS_DECODE_ARGS variable in cpp_builder.py (#132615)
[ROCm][CK][Inductor] Enable addmm for CK backend to gemm max autotune (#130576)
[inductor] Default to 1 compile thread for internal (#132540)
[inductor] support vectorization for torch.any(bool) -> bool (#132472)
[inductor] Replace torch.allclose with torch.testing.assert_close in test_fx_fusion (#130618)
[Inductor] Small performance, precision, and dependency updates to B2B-GEMM (#132354)
[Easy] log output code path on cache hit (#132718)
[inductor] switch AotCodeCompiler to new cpp_builder. (take 3) (#132766)
Stop using preserve_rng_state as decorator (#132774)
fix autotuning init issues (#132837)
[inductor] disable capture_pre_autograd_graph related UTs on Windows (#132848)
[CUDAGraph] Warn once if too many distinct sizes (#132832)
Make inductor kernel metadata comments more descriptive (#126698)
AutoHeuristic: mixed_mm H100 heuristic (#132685)
Stop using with_fresh_cache_if_config as decorator (#132801)
Don't generate stack entry for DebugContext.wrap (#132802)
Don't use _disable_current_modes as decorator (#132809)
[inductor] raise unsupport msg in capture_pre_autograd_graph on Windows (#132841)
[Inductor] Support use_libdevice_for_f64 for pointwise ops on XPU, align with CUDA. (#132739)
[inductor] disable test_torchinductor failed UTs on Windows (#132973)
[inductor] Disable remote caching in failing test_cpu_repro tests (#132955)
[AOTI] Fix complex64 not defined (#132810)
[ROCm][Inductor] Enable AOT Inductor CPP UTs for ROCm (#131521)
[inductor] tensor_is_align fallbacking False if unbacked expr not comptime evaled (#132423)
[export] Merge functions in replace set_grad/autocast with HOO (#132724)
[aoti] forward fix of [inductor] switch AotCodeCompiler to new cpp_builder. (take 3) (#133042)
Add explicit GQA support. (#131559)
AutoHeuristic: tuned_mm (#131615)
inductor mm autotuning: add back previously pruned configs (#131616)
Fix autotuning for flex_decoding (#132157)
[inductor] cpp_builder add dynamo time trace for compile_file (#133103)
[inductor] remove debug code of AotCodeCompiler (#132823)
[inductor] remove deprecated cpp_builder implementation. (#133161)
[Inductor][Intel GPU] Support codegen empty_strided_xpu, align with #118255. (#126678)
[inductor] remove dtype check/assert for reduction vec and support bool for min/max (#132473)
Add support for returning LSE from FlexAttention (and also differentiating through it) (#133159)
mixed_mm: fix segfault when allow_tf32=True (#133173)
[inductor] add FreeLibrary to DLLWrapper for Windows. (#133184)
[inductor] Add some more reinplacing tests (#132839)
[Inductor] support masked vectorization for the tail_loop of the 2d tiles kernel (#130724)
[Inductor] support masked vectorization for the tail_loop for INT8 datatype (#131155)
Turn off remote caching in unit tests unless explicitly on (#133258)
[inductor] process compile_only case in all build options class. (#129975)
[inductor][test] Fix test_vertical_pointwise_reduction_fusion (#133276)
Reland "[2/2] PT2 Inductor ComboKernels - automatic horizontal fusing (#131675)" (#133291)
[inductor] Fix test_codecache::test_inductor_counters (#133244)
[Inductor][FlexAttention] Support non-divisible sequence lengths (#133019)
[inductor] [cpp] fix the reindexer from template_buffer to Y (#133070)
Bump maxinum num warps (#132458)
Add an option to use do_bench_using_profiling in TORCHINDUCTOR_PROFILE (#133523)
Restore mixed dtypes GEMM auto-tuning for Ampere (#129058)
AutoHeuristic: tests (#133496)
[inductor][cpp][gemm] improve large bs perf with better cache blocking (#132729)
AutoHeuristic: Enable explicit support for ranking (#131710)
[ROCm][CK][Inductor] enable dynamic shapes for CK backend to gemm max autotune (#133285)
Add auto-tuning for sparse semi-structured MM operator (#123742)
overestimate time_taken_ns for autotuning (#133633)
[inductor] [cpp] fix accuracy when template_buffer has users other than the epilogue nodes (#133073)
[inductor][cpp][gemm] fix k-slicing bug and add thread blocking config (#132730)
AutoHeuristic: Heuristic that ranks choices for mm (#131714)
mixed_mm: add more extensive dtype testing (#133292)
[inductor] make conv template work with symbolic stride/padding (#132938)
[Inductor][FlexAttention] Small cleanup for FlexAttention kernel template (#133664)
Move the layout constraint registration of aten._scaled_mm.default to module scope (#133669)
[inductor] clean up TODO comments. (#133718)
[Inductor][CPP] Refactor the tiling select into a standalone module to enhance its extensibility (#130892)
[inductor] Fix test_cudagraph_trees_expandable_segments.py for internal (#133698)
Add a fudge factor to ephemeral NCCL timeout increase (#133722)
[inductor][cpp][gemm] easy: adjust indentation of template, var renaming etc. (#133312)
[Inductor][CPP] Align Half load with BFloat16 load (#132011)
Lower cache mocking to test more pytorch code (#133579)
Warn on fx graph cache bypass and log it to tlparse (#133826)
[AOTI] Introduce DeferredCudaKernelLine for cuda cpp wrapper (#129135)
[BE] Fix MYPY issues (#133872)
[inductor] enable inductor backend for dynamo on Windows. (#133921)
[inductor] Use int64_t as index type for all platfroms 4 (#133892)
[Inductor][FlexAttention] Don't trigger dynamic shape on building empty block mask (#133836)
[inductor] prune unused constants in graph scheduling (#132208)
Safely infer device type + docstrings + tests (#133668)
[Inductor] Move GPU_TYPE(The runtime avaliable gpu type, cuda or xpu) from (#132740)
[Inductor] Support _check_triton_bf16_support on XPU. (#132748)
[Inductor] Moves intermediary tensors which are constructed on the cpu to XPU when safe, align with CUDA. (#132843)
[BE][Ez]: FURB142,FURB92 misc preview fixes (#133880)
[inductor] calibration inductor windows uts (1/N) (#134033)
[inductor] write cpp code with encoding utf-8 (#134027)
[Inductor][FlexAttention] Respect user's input kernel_options (#134065)
[AOTI][Tooling] Add a test case where config.debug_intermediate_value_printer=True to check codegen (#133326)
[inductor] fix signbit build fail on Windows. (#134229)
[inductor] fix dynamic size array(vla) build error on msvc v4 (#134221)
[Inductor][FlexAttention] Fix IS_DIVISIBLE bug and add unit tests (#134055)
[FlexAttention]Fix how we realize input buffers (#134351)
[inductor] Remove dead code in multi_kernel.py (#134194)
[inductor] Move imports to top of file in generated code (#134195)
Add option to skip functional passes in the pattern matcher's replacement graph (#134364)
[inductor] calibration inductor windows uts (2/N) (#134358)
[Inductor][FlexAttention] Rename IS_LAST_BLOCK to CHECK_BLOCK_BOUNDARY (#134378)
[inductor] fix munge_exc not support windows path (#134348)
[AOTI][CPU] Make int8 qlinear work (#134368)
[PT2] use statically_known_true in slice_noop (#134270)
[inductor] fix test torch package working with trace on windows (#134397)
[inductor] calibration inductor windows uts (5/N) (#134402)
[inductor] calibration inductor windows uts (3/N) (#134400)
[inductor] calibration inductor windows uts (4/N) (#134401)
[inductor] calibration inductor windows uts (6/N) (#134419)
[inductor] calibration inductor windows uts (7/N) (#134420)
[inductor] fix test_functional_call_sequential_params_and_buffers expectation on Windows (#134394)
[inductor] support vec for atomic add (#131314)
[inductor] calibration inductor windows uts (8/N) (#134424)
[inductor] calibration inductor windows uts (10/N) (#134426)
[inductor] calibration inductor windows uts (11/N) (#134427)
[inductor] fix _maybe_subprocess_run not support Windows path (#134365)
[aoti] remove c_shim_version v1 logic (#134283)
Support larger page sizes with use_mmap_weights (#131000)
Fix lint failures (#134488)
relax unification checks when size-like symbols can be 0 (#133112)
[CUDAGraph] skip cudagraph if too many distinct sizes (#131387)
[inductor] Improve sort kernel perf (#131719)
make _inductor.config.rocm.supported_arch set order deterministic for caching (#131921)
Mode to emulate amp numerics (#131595)
Back out "[1/2] PT2 Inductor ComboKernels - Foreach cases (#124969)" (#132065)
[Inductor] Refactor autotuning utils to compute max block sizes (#131730)
[PT2][Optimus] Optimize cat node inputs pattern (#131866)
[PT2] Port fuse_chunk_reshape_unsqueeze_concat_pass to PT2 pre_grad passes (#131902) (#132078)
[PT2][Optimus] Add unbind cat to view pass (#132152)
Make config.autotune_remote_cache be a three-way option (#132285)
[inductor] Reinplacing should not allow an op to mutate the same input multiple times (#132238)
[AOTI][refactor] Move set_cpp_kernel to base class (#132319)
[AOTI][refactor] Consolidate how python_kernel_name is set (#132320)
[PT2][Optimus] Add missing example value for introduced nodes (#132297)
Add try except for _maybe_evaluate_static call in IndexPropagation (#132128)
Reland "[1/2] PT2 Inductor ComboKernels - Foreach cases (#124969)" (#132182)
Scale XBLOCK in triton reduction configs to avoid hitting max grid (#128826)
make functorch CSE respect mutations as barriers (like fsdp.set_) (#132243)
[AOTI] Switch to use shim v2 for fbcode (#132750)
[PT2][Optimus] Add unbind_stack_to_cat_pass (#132542)
[Inductor] support masked vectorization for the tail_loop (#126526)
[inductor] check best templates first for fusions (#132829)
[BC breaking] move benchmarking + prefer inductor path (#132827)
[AOTI][tooling][1/n] Add intermediate value debug printer (#132323)
[AOTI][refactor] Update MKLDNN ops cpp wrapper support (#132367)
Fix inf value reduction in non persistent reduction for scans (#132293)
[PT2][Optimus] Update unbind_cat_to_view pass to include more complicated cases (#132831)
[Inductor] Add config option to force higher-dimensional tiling (#132937)
dynamic shapes mismatch errors (#132982)
Fix fbcode AOTI GPU lowering for ARM64 hosts (#133017)
[AOTI][Tooling] A couple fixes / minor updates for initial debug printer (#133016)
[PT2][Optimus] Extend split_stack_to_cats when split and stack have different dims (#133060)
[AOTI] Disable split_cat_aten passes (#133014)
[AOTI] Switch fbcode HIP to C shim version v2 (#133105)
Minor type annotation updates following up D60954888 (#133382)
typing for remote_cache (#133446)
Fix triton codegen with math.trunc (#133354)
[PT2] Consolidate args and kwargs usage in pre_grad passes (#133518)
[PT2][Optimus] Add missing example value for the nodes introduced in group batch fusion (#133414)
Fix printing symfloat pow in triton (#133614)
AutoHeuristic: mm ranking heuristic h100 (#133608)
[PT2][Optimus] Add unbind_stack_to_slices pass (#133420)
Add message text to BypassFxGraphCache exceptions. (#133505)
[Inductor] short-term fix for needs_fixed_stride_order silent incorrectness (#133452)
Disable unwrapping scalar tensors when used as outputs (#132859)
[PT2][Optimus] Fix mixed precison training problem in decompose mem bound (#133626)
Add a smaller default config option for decode (#133646)
[PT2] Port remove_noop to PT2 pre_grad passes (#132183)
Scale XBLOCK in triton for pointwise (#133300)
[pytorch][counters] add pytorch.wait_counter.fx_codgen_and_compile (#133107)
[PT2][Optimus] Add move reshape out of split stack pass (#133710)
[PT2] Add a pass to convert stack to unsqueeze cat (#133966)
Migrate fuse_chunk_reshape_concat_pass to PT2 (#134026)
Allow SymInts and SymFloats as other in div_softmax_pattern (#133989)
[Inductor/Triton] Customize triton codegen to optionally preserve input dtype on tl.load (#132406)
ppc64le: VSX Support for Inductor (#132746)
Unify lowerings for auto_functionalized and triton_kernel_wrapper_functional (#134466)
Update partitioner's is_fusible heuristic to respect auto_functionalized (#134490)
[aotinductor][UserDefinedTritonKernel] fix case with non-constexpr params declared after autotuned params (#134520)
[AOTI][Tooling][4/n] Add torch.save() for individual intermediate tensor (#133871)
[Inductor][Refactor] Rename CPU benchmark test configs (#134639)
[AOTI][Tooling] Follow up to print location of saved file path for torch.pickle_save() (#134651)
[Inductor] add inductor config: masked_vec (#134566)
Never CSE aten.empty in the partitioner (#134703)
[PT2] Fix node metadata setting in group_batch_fusion_aten (#134543)
Fix AOTInductor complication on ROCM (#134522)
[inductor] enable Intel Compiler(icx-cl) for inductor windows (#134772)
Enable cudagraphs in cpp wrapper (#133885)
dynamic shapes for combo_kenel/foreach_kernel (#134477)
[PT2][Optimus] Skip meta update on symblic shape (#134975)
Redesign custom op functionlaization for better re-inplace  (#134409)
[inductor] Improve compile time regression from MemoryDep.normalize (#135070)
Add Inductor config for default stride behavior (#135238)
[Inductor] Optionally allow padding on non-GPU devices (#135280)
[inductor][cpp][gemm] reduce memory alloc overhead by allocating local acc once per thread (#135277)
[inductor][cpp][gemm] enable dynamic M for k-slicing (#133447)
